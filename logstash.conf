input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["transactions"]
    group_id => "logstash"
  }
}

filter {
  json {
    source => "message"
    target => "transaction"
  }

  # Optionally remove the original message field if it's no longer needed
  mutate {
    remove_field => ["message"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "transactions"
    # If you want to store parsed JSON fields at the root level, use this
    document_id => "%{[parsed_message][accountId]}-%{+YYYY.MM.dd.HH.mm.ss}"
    # Store parsed JSON fields as is, no target specified
    # document_id => "%{accountId}-%{+YYYY.MM.dd.HH.mm.ss}"
    # index => "transactions"
  }
  stdout { codec => rubydebug }
}
